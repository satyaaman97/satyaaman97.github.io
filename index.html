<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Aman Satya - Resume</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body { font-family: Arial, sans-serif; margin: 0; padding: 0; background: #f9f9f9; color: #222; }
    .container { max-width: 900px; margin: 40px auto; background: #fff; padding: 40px; border-radius: 10px; box-shadow: 0 2px 8px rgba(0,0,0,0.07); }
    h1, h2, h3 { color: #3262a8; }
    h1 { margin-top: 0; }
    .section { margin-bottom: 32px; }
    .label { font-weight: bold; color: #444; }
    ul { margin: 8px 0 8px 24px; }
    .job-title { font-weight: bold; font-size: 1.1em; }
    .job-location { color: #666; font-size: 0.98em; }
    .job-date { color: #888; font-size: 0.95em; }
    .contact { margin-bottom: 10px; }
    @media (max-width: 600px) {
      .container { padding: 16px; }
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>Aman Satya</h1>
    <div class="section">
      <div class="contact"><span class="label">Phone:</span> 9319257650</div>
      <div class="contact"><span class="label">Email:</span> <a href="mailto:aman.sat.official@gmail.com">aman.sat.official@gmail.com</a></div>
    </div>
    <div class="section">
      <h2>Summary</h2>
      <p>
        Big Data Engineer with strong experience in building scalable data pipelines, real-time analytics platforms, and distributed data systems. Proven track record in supporting business and analytics teams through efficient data solutions. Interested in optimising spark jobs, real-time data processing, and studying about OLAP database internals.
      </p>
    </div>
    <div class="section">
      <h2>Education</h2>
      <ul>
        <li>
          <strong>MS in Computer Science</strong><br>
          University of Colorado Boulder, Boulder, CO, USA<br>
          <span class="job-date">Aug 2019 - May 2021</span>
        </li>
        <li>
          <strong>BE in Computer Science</strong><br>
          BMS College of Engineering, Bengaluru, KA, India<br>
          <span class="job-date">Aug 2015 - May 2019</span>
        </li>
      </ul>
    </div>
    <div class="section">
      <h2>Key Skills</h2>
      <p>
        <span class="label">Languages:</span> Python, SQL, Java, Shell scripting<br>
        <span class="label">Tools & Frameworks:</span> Hadoop, Hive, PySpark, Spark streaming, Kafka, Kafka Streams, Apache Pinot, Apache Airflow, Flask, Docker, Kubernetes, DBT, MongoDB
      </p>
    </div>
    <div class="section">
      <h2>Professional Experience</h2>
      <div>
        <div class="job-title">Big Data Engineer</div>
        <div class="job-location">Amar Ujala Web Service | Noida, UP</div>
        <div class="job-date">Jun 2024 - Present</div>
        <ul>
          <li>Setup and deployed a 5-node Hadoop cluster; optimized HDFS and YARN configurations for stability and performance</li>
          <li>Configured YARN Fair Scheduler with custom priority pools to manage Spark workloads efficiently across shared resources</li>
          <li>Scheduled internal Hadoop maintenance jobs (replication, checkpointing, HDFS rebalancing) at time of the day based on cluster load to minimize performance impact and maintain balanced data distribution</li>
          <li>Built and managed real-time data pipelines using Kafka and Spark Structured Streaming to capture user-generated events from Amar Ujala web properties, ingesting 20–25 GB of data daily (max 50gb) to support AU360 analytics dashboards and data science initiatives</li>
          <li>Developed real-time Spark Structured Streaming jobs to ingest published stories data into Delta Lake, performing upserts to keep content updated and consistent</li>
          <li>Developed additional Spark Structured Streaming jobs to track story performance in real time using sliding windows (30-minute window sliding every 1 minute), enabling quick insights into content engagement</li>
          <li>Created Spark ETL jobs processing 1–2 TB of data daily to support 15 AU360 analytics dashboards and reports, with more currently in development</li>
          <li>Stored gold-level curated data in Hive for reporting and business intelligence consumption</li>
          <li>Built RESTful APIs using Flask to expose processed data and analytics to the AU360 platform</li>
          <li>Developed a heuristic-based story recommendation system for the AU app homepage using story trendiness and view count metrics</li>
          <li>Orchestrated various batch jobs using Apache Airflow, ensuring reliable and timely data workflows</li>
          <li>Leading the building of real-time analytics platform by setting up Apache Pinot as a low-latency OLAP datastore by using docker; tracked real-time E-paper subscriptions on Pinot using hybrid tables</li>
          <li>Implemented Kafka Streams to flatten and transform amar ujala app feed data before ingesting into Apache Pinot for real-time query-ability</li>
          <li>Developed a Transformer Pipeline to convert deeply nested, unstructured story data into structured formats, and ingested it into Apache Pinot. Implemented various indexing strategies to enable high-performance querying</li>
          <li>Building a Data Augmentation Service using Java Spring Boot to consolidate multiple data sources into a unified, big Pinot table (OBT ~200 columns) for majority of analytical use cases. Leveraging stateless operations and intelligent caching to ensure real-time performance with zero latency</li>
          <li>Planned the capacity of the Apache Pinot cluster and created clear, well-structured YAML files with all necessary configurations, including resource limits for each component, to enable smooth deployment using Docker and Kubernetes</li>
          <li>Collaborated with Product, Sales, and Data Science teams to deliver ad-hoc data requests and insights to support business decisions</li>
        </ul>
      </div>
      <div style="margin-top:20px;">
        <div class="job-title">Software Development Engineer-1</div>
        <div class="job-location">Network 18 Media and Investments Ltd | Noida, UP</div>
        <div class="job-date">Aug 2022 - May 2024</div>
        <ul>
          <li>Built an in-house data platform to handle ~1TB of daily user data from Moneycontrol and News18, as part of a POC to replace Clevertap for long-term storage. Used PySpark and DBT to prepare user-centric datasets, and implemented Data Vault 2.0 modeling to store users and their corresponding event data</li>
          <li>Expanded features on push notification service of news18 app. Improved user experience by resolving duplicate notifications for News18 app</li>
          <li>Improved response time of notification service from 15 to 3 sec by lowering notification service database throughput by rewriting the logic of middle-ware in node js and express</li>
        </ul>
      </div>
      <div style="margin-top:20px;">
        <div class="job-title">Data Engineer</div>
        <div class="job-location">Zee5 | Bengaluru, KA</div>
        <div class="job-date">Jul 2021 - Aug 2022</div>
        <ul>
          <li>Created a data pipeline for attributes around ad-effectiveness from Mixpanel/Appsflyer for ~1000 Zee5 advertisers</li>
          <li>Managed an ETL pipeline to ingest user-specific data (~2TB data per day) from Conviva based on Zee5 content, delivering insights to stakeholders like Vodafone and Tata Sky</li>
        </ul>
      </div>
      <div style="margin-top:20px;">
        <div class="job-title">Data Scientist Intern</div>
        <div class="job-location">Abound (ex-Times Club) | Redwood City, CA, USA</div>
        <div class="job-date">Jul 2020 - Aug 2020</div>
        <ul>
          <li>Developed a ranking model to prioritize merchant on-boarding onto the app, led to increased user retention by 5%</li>
        </ul>
      </div>
    </div>
  </div>
</body>
</html>
